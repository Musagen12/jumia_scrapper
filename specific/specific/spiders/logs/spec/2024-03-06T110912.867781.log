2024-03-06 11:09:19 [scrapy] DEBUG: Crawled (200) <GET https://www.jumia.co.ke/lenovo-xg01-earphones-wireless-bluetooth-5.0-headphone-179703402.html> (referer: None)
2024-03-06 11:09:19 [scrapy] ERROR: Error processing {'availability': 'In stock',
 'product_brand': 'Lenovo',
 'product_image': 'https://ke.jumia.is/unsafe/fit-in/500x500/filters:fill(white)/product/20/4307971/1.jpg?0724',
 'product_name': 'Lenovo XG01 Earphones Wireless Bluetooth 5.0 Headphone',
 'product_price': 'KSh 2,971',
 'product_url': 'https://www.jumia.co.ke/lenovo-xg01-earphones-wireless-bluetooth-5.0-headphone-179703402.html'}
Traceback (most recent call last):
  File "/home/colonel/jumia_scrapper/env/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/colonel/jumia_scrapper/env/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/colonel/jumia_scrapper/specific/specific/pipelines.py", line 36, in process_item
    adapter[price_key] = float(value4)
ValueError: could not convert string to float: ' 2,971'
2024-03-06 11:09:19 [scrapy] INFO: Closing spider (finished)
2024-03-06 11:09:19 [scrapy] INFO: Stored json feed (0 items) in: tracked_item_data.json
2024-03-06 11:09:19 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 285,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 31252,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 6.43685,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 3, 6, 9, 9, 19, 348408, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 117071,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 89714688,
 'memusage/startup': 89714688,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 3, 6, 9, 9, 12, 911558, tzinfo=datetime.timezone.utc)}
2024-03-06 11:09:19 [scrapy] INFO: Spider closed (finished)
